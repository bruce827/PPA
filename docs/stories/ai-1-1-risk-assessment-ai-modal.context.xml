<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>AI</epicId>
    <storyId>1.1</storyId>
    <title>AI风险评估弹窗组件</title>
    <status>drafted</status>
    <generatedAt>2025-11-09</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/ai-1-1-risk-assessment-ai-modal.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>项目评估人员</asA>
    <iWant>在风险评分步骤中点击"一键AI评估"按钮并上传/粘贴项目文档</iWant>
    <soThat>AI能够分析文档并提供风险项评分建议,节省手动分析时间</soThat>
    <tasks>
      - 创建AI评估Modal组件（AIAssessmentModal.tsx）
      - 在RiskScoringForm集成AI评估区域和按钮
      - 实现提示词加载功能（从/api/ai/prompts获取）
      - 实现AI评估功能（调用/api/ai/assess-risk）
      - 实现parseAIResponse函数解析AI模型原始响应
      - 将AI响应格式化为AssessmentResult标准结构
      - 验证解析后数据的完整性和有效性
      - 实现评估结果展示（风险项评分建议表格、缺失风险项列表、总体建议）
      - 实现应用评估结果到表单功能
      - 添加样式和UI优化（AIAssessmentModal.less）
      - 错误处理和用户反馈（空文档、未选择提示词、API失败、响应解析失败）
      - 集成测试（打开Modal、评估流程、应用结果、格式错误处理）
    </tasks>
  </story>

  <acceptanceCriteria>
    AC1: AI评估按钮和弹窗触发 - 在风险评分表单下方显示AI评估区域，点击按钮打开Modal
    AC2: 项目文档输入功能 - 提供5000字以内的多行文本输入框，显示字符计数
    AC3: 提示词选择和配置 - 下拉选择提示词模板，动态显示变量配置区域
    AC4: 开始AI评估功能 - 验证输入，调用后端API /api/ai/assess-risk，接收AI模型原始响应，解析并格式化为规范结构，验证数据完整性
    AC5: 评估结果展示 - 显示风险项评分建议表格、缺失风险项Alert、总体建议Card
    AC6: 应用评估结果到表单 - 将AI建议的评分自动填充到风险评分表单，关闭Modal
    AC7: 错误处理 - 处理空文档、未选择提示词、API调用失败、响应解析失败等错误情况
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc path="docs/new-assessment-ai-design-step1.md" title="AI一键风险评估功能设计" section="详细设计">
        详细描述了RiskScoringForm组件中AI功能的集成位置、AI评估弹窗设计（包含文档输入、提示词配置、评估结果展示）、后端API设计（/api/ai/assess-risk, /api/ai/prompts）、AI服务实现（提示词构建、模型调用、响应解析）和结果应用逻辑。
      </doc>
      <doc path="docs/tech-spec.md" title="技术规范文档" section="总体架构设计">
        项目采用React 18 + Ant Design Pro 5 + TypeScript前端技术栈，Node.js + Express + SQLite后端架构。前端端口8000，后端端口3001。包含API架构设计、数据库设计、前端项目结构等技术细节。
      </doc>
      <doc path="docs/PRD.md" title="产品需求文档" section="AI功能集成">
        AI功能旨在提升评估效率和准确性，通过分析项目文档自动评估风险项评分。需要集成提示词管理、模型配置、AI评估服务等模块。
      </doc>
    </docs>
    <code>
      <artifact path="frontend/ppa_frontend/src/pages/Assessment/components/RiskScoringForm.tsx" kind="component" symbol="RiskScoringForm" lines="1-76" reason="需要在此组件中添加AI评估Section和AIAssessmentModal集成。当前组件使用ProForm布局，包含风险项选择表单和一键填充样例数据按钮。">
      </artifact>
      <artifact path="frontend/ppa_frontend/src/pages/Assessment/New.tsx" kind="page" symbol="NewAssessmentPage" lines="1-300" reason="评估向导主页面，管理步骤状态和表单数据。需要添加handleAIAssessmentComplete函数处理AI评估结果应用。">
      </artifact>
      <artifact path="frontend/ppa_frontend/src/utils/rating.ts" kind="utility" symbol="summarizeRisk, parseRiskOptions" lines="1-100" reason="风险评分计算工具函数，用于解析风险选项和汇总风险评分。AI评估结果应用时需要保持一致的数据格式。">
      </artifact>
      <artifact path="frontend/ppa_frontend/src/pages/ModelConfig/Prompts/Form.tsx" kind="component" symbol="PromptTemplateForm" lines="1-300" reason="提示词模板表单组件示例，展示了如何使用Ant Design Form、TextArea、Select等组件，以及提示词变量管理的实现方式。">
      </artifact>
      <artifact path="frontend/ppa_frontend/src/pages/ModelConfig/Prompts/components/PreviewModal.tsx" kind="component" symbol="PreviewModal" lines="1-150" reason="预览Modal示例，展示了Modal组件的使用方式、Form集成、变量填写UI等，可作为AIAssessmentModal实现的参考。">
      </artifact>
    </code>
    <dependencies>
      <node>
        <package name="react" version="18+" />
        <package name="antd" version="5+" />
        <package name="@ant-design/pro-components" version="2+" />
        <package name="typescript" version="5+" />
        <package name="@umijs/max" version="4+" />
      </node>
    </dependencies>
  </artifacts>

  <constraints>
    - 必须使用Ant Design组件库（Modal, Input.TextArea, Select, Table, Card, Alert, Spin, Button, message）
    - 遵循UMI Max项目结构和TypeScript类型定义
    - Modal宽度设置为1000px，支持响应式设计
    - 项目文档输入限制5000字，需显示字符计数
    - 提示词API (/api/ai/prompts) 需在后续Story中实现，当前可使用mock数据
    - AI评估API (/api/ai/assess-risk) 需在后续Story中实现
    - 后端API返回AI模型原始响应，前端负责解析和格式化
    - 必须实现鲁棒的AI响应解析逻辑，支持JSON和纯文本格式
    - 解析后必须验证risk_scores数组存在且每项包含必填字段
    - 所有状态管理使用React useState hooks
    - Modal关闭时必须重置所有内部状态
    - 错误处理使用Ant Design message组件提供用户反馈
    - 响应格式错误时应提供友好的错误提示，不应导致应用崩溃
    - 代码文件路径必须遵循项目约定：frontend/ppa_frontend/src/pages/Assessment/components/
  </constraints>

  <interfaces>
    <api name="/api/ai/prompts" kind="GET" signature="GET /api/ai/prompts" path="server/routes/ai.js">
      获取可用的AI提示词模板列表。返回格式：{ success: true, data: [{ id, name, description, content, variables }] }
      此API需在后续Story中实现。
    </api>
    <api name="/api/ai/assess-risk" kind="POST" signature="POST /api/ai/assess-risk" path="server/routes/ai.js">
      执行AI风险评估。请求体：{ document, prompt, variables, currentRiskItems, currentScores }
      返回格式：{ success: true, data: { raw_response: string, model_used: string, timestamp: string } }
      注意：返回的是AI模型的原始响应，前端需要解析raw_response字段并格式化为AssessmentResult结构。
      此API需在后续Story中实现。
    </api>
    <interface name="Prompt" kind="TypeScript Interface" signature="interface Prompt { id: string; name: string; content: string; variables?: { name: string; default_value?: string }[] }">
      提示词对象类型定义。
    </interface>
    <interface name="AssessRiskRequest" kind="TypeScript Interface" signature="interface AssessRiskRequest { document: string; prompt: Prompt; variables: Record<string, string>; currentRiskItems: RiskItem[]; currentScores: Record<string, number> }">
      AI评估请求类型定义。
    </interface>
    <interface name="AssessmentResult" kind="TypeScript Interface" signature="interface AssessmentResult { risk_scores: { item_name: string; suggested_score: number; reason: string }[]; missing_risks?: { item_name: string; description: string }[]; overall_suggestion: string; confidence?: number }">
      AI评估结果类型定义（前端格式化后的标准结构）。
    </interface>
    <interface name="AIModelRawResponse" kind="TypeScript Interface" signature="interface AIModelRawResponse { success: boolean; data: { raw_response: string; model_used: string; timestamp: string }; error?: string }">
      后端API返回的AI模型原始响应格式。raw_response可能是JSON字符串或纯文本。
    </interface>
    <interface name="parseAIResponse" kind="Function" signature="function parseAIResponse(rawResponse: string): AssessmentResult">
      解析AI模型原始响应的工具函数。支持JSON格式和纯文本格式，返回标准化的AssessmentResult结构。
    </interface>
  </interfaces>

  <tests>
    <standards>
      本项目当前主要使用手动测试。建议在实现后进行：
      1. 组件渲染测试：AIAssessmentModal组件能正常打开和关闭
      2. 状态管理测试：文档输入、提示词选择、评估结果显示状态正确更新
      3. 事件处理测试：按钮点击、表单提交、Modal关闭等事件处理正确
      4. 集成测试：完整的AI评估流程（打开Modal → 输入文档 → 选择提示词 → 开始评估 → 查看结果 → 应用结果）
      5. 错误处理测试：空文档验证、未选择提示词验证、API调用失败处理
      6. UI测试：样式正确、响应式设计、字符计数显示、加载状态显示
      
      测试重点：
      - Modal打开和关闭不影响主表单状态
      - 应用评估结果后表单数据正确更新
      - 错误情况下用户获得明确的反馈信息
    </standards>
    <locations>
      frontend/ppa_frontend/src/pages/Assessment/components/__tests__/
    </locations>
    <ideas>
      - AC1测试：模拟点击"一键AI评估"按钮，验证Modal visible状态变化
      - AC2测试：测试TextArea输入，验证字符计数显示和5000字限制
      - AC3测试：测试提示词选择，验证变量配置区域动态显示
      - AC4测试：测试开始评估按钮，验证空文档和未选择提示词的警告消息
      - AC4+测试：mock AI原始响应（JSON和纯文本），验证parseAIResponse函数正确解析
      - AC4++测试：测试格式错误的AI响应，验证解析失败时的错误处理
      - AC5测试：mock解析后的评估结果，验证结果表格、Alert、Card的正确渲染
      - AC6测试：测试应用评估结果，验证form.setFieldsValue被调用且参数正确
      - AC7测试：mock API失败响应和解析错误，验证错误消息显示且loading状态重置
    </ideas>
  </tests>
</story-context>
