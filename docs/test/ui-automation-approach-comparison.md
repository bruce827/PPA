# UI 自动化两种技术路线对比备忘

**场景**：PPA 项目在考虑 UI 自动化回归测试时的技术选型对比与结论备忘。  
**候选方案**：
- 方案 A：模型 + Chrome DevTools MCP 驱动浏览器完成 UI 测试  
- 方案 B：Playwright + Python（或 TypeScript）做传统 UI 自动化测试

---

## 1. 总体结论

- 作为**长期可维护的回归测试框架**，更推荐以 **Playwright + Python/TS** 作为主力：  
  - 成熟度高，有完整的断言、报告、并行、CI 集成能力；  
  - 对团队协作、代码评审、问题排查更友好。  
- **Chrome DevTools MCP** 更适合用作：  
  - 模型驱动的“智能冒烟测试”“探索性测试”与“辅助调试工具”；  
  - 不是严格意义上最稳妥的回归测试唯一技术栈。

---

## 2. 关键维度对比

### 2.1 成熟度与生态

- **Playwright + Python**
  - 成熟的测试框架：内置测试 runner、断言库、trace 录制回放、截图、HTML 报告等。  
  - 社区生态完善，大量实践文章与问题解决方案。
- **Chrome DevTools MCP**
  - 面向“让模型能控制浏览器”的能力，本身不是完整测试框架。  
  - 需要在上层自行设计：用例管理、断言结构、报告与重试策略。

### 2.2 可维护性与协作

- **Playwright**
  - 测试用例 = 代码，结构清晰，可读性强，适合代码评审与长期维护。  
  - 能与 `docs/regression-test-plan.md`、PRD 中的 FR 条目一一对应成测试函数。
- **MCP**
  - 更多是“代理脚本 + 自然语言指令”，对个人使用友好，但脚本结构相对松散。  
  - 分不清“脚本写法问题 / 模型理解偏差 / 页面真有 bug”时，排查成本较高。

### 2.3 稳定性与可重复性

- **Playwright**
  - 对等待、超时、选择器稳定性有成熟方案，适合做发布门槛级的 P0 回归。  
  - 支持重试策略、失败时的 trace 诊断。
- **MCP**
  - 强依赖模型对 DOM 的理解与定位能力，天然更有不确定性。  
  - 更适合作“快速跑一遍看看有没有大问题”，而不是“必须 100% 通过才允许上线”的门槛。

### 2.4 与 LLM 的集成体验

- **Playwright**
  - 模型可以辅助生成或重构测试代码，但执行是传统 runner。  
  - 一旦生成并打磨好，用例本身是稳定资产。
- **MCP**
  - 模型直接从 PRD/需求理解 → 生成操作计划 → 驱动浏览器 → 再根据结果调整操作，非常灵活。  
  - 非常适合“临时探索、调试、冒烟”，而不是结构化、可审计的测试资产。

### 2.5 CI/CD 集成

- **Playwright**
  - 极易接入 GitHub Actions / GitLab CI / Jenkins，跑完出完整报告。  
  - 适合作为 Alpha→RC→正式版过程中稳定的质量门槛。
- **MCP**
  - 需要额外部署 MCP server + Chrome 环境，并在 CI 中编排模型调用工作流。  
  - 工程化与资源成本更高，目前更适合本地或开发环境辅助使用。

---

## 3. Chrome DevTools MCP 的典型应用场景

当前更合理的定位是“**AI 驱动的浏览器操作与调试助手**”，典型应用包括：

1. **AI 辅助前端调试与问题定位**
   - 打开指定页面，自动检查：
     - 控制台报错、Network 请求失败；  
     - 某按钮/组件是否存在、是否被遮挡，CSS 是否异常；  
     - DOM 结构与 PRD 描述是否一致。  
   - 帮助快速回答：“这个按钮点不了是因为谁挡住了？”、“这条 API 返回 500 时 UI 是什么表现？”

2. **临时冒烟 / 轻量回归**
   - 代码改完后，让模型通过 MCP：
     - 打开 `/assessment/new`，按 PRD 填一遍表单，看是否能顺利保存；  
     - 打开 `/dashboard`，看主要卡片是否渲染、页面是否有明显错误提示。  
   - 结果不一定形成正式报告，但能快速发现重大问题。

3. **信息采集与页面内容结构化**

   - 让模型浏览多个页面，采集表格/列表内容，整理成 JSON/CSV：  
     - 例如扫描历史项目页面，把关键字段结构化输出，辅助分析；  
     - 或从外部网站抓取某些配置/参数，转成系统可用的数据格式。

4. **交互式产品评审 / UX 检查**

   - 给模型一份 UX 规范或文案规范，让它通过 MCP：
     - 检查按钮文案是否统一；  
     - 检查必填项是否有明显提示；  
     - 检查加载态/错误态是否有妥善反馈。  
   - 更偏向“智能产品体验检查”，而不是精确的功能验证。

5. **辅助生成和校正测试脚本**

   - 模型通过 MCP 真实“走一遍”业务流程：  
     - 记录操作步骤和观察到的 DOM；  
     - 反向生成 Playwright/Cypress 测试代码草案；  
     - 根据实际页面结构，推荐更稳定的选择器和断言条件。  
   - 这样 MCP 成为“测试脚本生成器/助手”，而不是最终执行引擎。

---

## 4. 对 PPA 项目的当前规划建议

- 当前阶段（个人使用、Alpha 阶段）：
  - 回归测试为时尚早，可主要利用 MCP 做：临时冒烟、探索性测试、辅助调试。  
  - 将关键流程（新建评估、导出、配置中心）用 MCP 跑一跑，帮助早期发现大故障即可。

- 未来阶段（RC / 多人使用后）：
  - 根据 `docs/test/regression-test-plan.md` 中的 P0 场景，用 **Playwright + Python/TS** 落地成稳定回归用例。  
  - MCP 继续扮演“智能助手”的角色：用于新需求验证、问题排查、自动生成或更新测试代码。

> 本文档仅作为技术路线对比备忘，方便后续在 PPA 项目进入 RC/多用户阶段时快速回顾当初的思考与选择依据。

